// test_prompts_naturais.js - Teste dos novos prompts mais soltos e naturais

const OPENAI = require('./open_ai/open_ai');

async function testNaturalPrompts() {
    console.log('ğŸ§ª TESTANDO PROMPTS MAIS NATURAIS E FLEXÃVEIS\n');

    const openaiService = new OPENAI();

    // Teste 1: AnÃ¡lise de mensagem com prompt mais solto
    console.log('1ï¸âƒ£ Testando anÃ¡lise de mensagem...');

    const testMessages = [
        "HÃ¡ alguma atividade",
        "Eish, que calor!",
        "Beira hoje",
        "Vai chover amanhÃ£?",
        "Que roupa posso usar"
    ];

    for (const message of testMessages) {
        try {
            console.log(`\nğŸ“ Mensagem: "${message}"`);

            const analysis = await openaiService.analyzeMessage(message, {
                queryCount: 5,
                lastCity: 'Beira',
                currentLocation: 'Maputo'
            });

            if (analysis.success) {
                console.log(`âœ… Intent: ${analysis.analysis.intent}`);
                console.log(`ğŸ“Š ConfianÃ§a: ${analysis.analysis.confidence}`);
                console.log(`ğŸ’­ Reasoning: ${analysis.analysis.reasoning}`);
            } else {
                console.log(`âš ï¸ Fallback usado: ${analysis.method}`);
            }

        } catch (error) {
            console.log(`âŒ Erro: ${error.message}`);
        }
    }

    // Teste 2: Resposta contextual com prompt mais natural
    console.log('\n\n2ï¸âƒ£ Testando resposta contextual...');

    const mockWeatherData = {
        city: 'Beira',
        temperature: 28,
        description: 'parcialmente nublado',
        humidity: 75,
        feelsLike: 31
    };

    const mockAnalysis = {
        intent: 'weather_query_current',
        confidence: 0.9,
        response_type: 'informative'
    };

    const mockUserContext = {
        queryCount: 3,
        expertiseLevel: 'basic',
        lastCity: 'Maputo'
    };

    try {
        const response = await openaiService.generateContextualResponse(
            mockAnalysis,
            mockWeatherData,
            mockUserContext
        );

        if (response.success) {
            console.log('âœ… Resposta contextual gerada:');
            console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
            console.log(response.message);
            console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
        }
    } catch (error) {
        console.log(`âŒ Erro resposta contextual: ${error.message}`);
    }

    // Teste 3: SugestÃµes baseadas na temperatura com prompt mais flexÃ­vel
    console.log('\n\n3ï¸âƒ£ Testando sugestÃµes baseadas na temperatura...');

    const temperatureTests = [
        { temp: 35, desc: 'sol intenso' },
        { temp: 22, desc: 'parcialmente nublado' },
        { temp: 16, desc: 'nublado' }
    ];

    for (const test of temperatureTests) {
        try {
            console.log(`\nğŸŒ¡ï¸ Testando ${test.temp}Â°C - ${test.desc}`);

            const weatherForSuggestions = {
                temperature: test.temp,
                description: test.desc,
                humidity: 70,
                city: 'Beira'
            };

            const suggestions = await openaiService.generateTemperatureBasedSuggestions(
                weatherForSuggestions,
                'Beira',
                { userPhone: 'teste' }
            );

            if (suggestions.success) {
                console.log(`âœ… SugestÃµes para ${test.temp}Â°C:`, suggestions.suggestions);
                console.log(`ğŸ”§ MÃ©todo: ${suggestions.method}`);
            } else {
                console.log(`âš ï¸ Fallback usado:`, suggestions.suggestions);
            }

        } catch (error) {
            console.log(`âŒ Erro sugestÃµes: ${error.message}`);
        }
    }

    // Teste 4: Verificar diferenÃ§a entre prompts antigos vs novos
    console.log('\n\n4ï¸âƒ£ Comparando estilo de prompts...');
    console.log('ğŸ”„ PROMPT ANTIGO: Muito estruturado, formal, categÃ³rico');
    console.log('âœ¨ PROMPT NOVO: Natural, conversacional, flexÃ­vel');
    console.log('\nğŸ“ Exemplo de diferenÃ§a:');
    console.log('ANTIGO: "SISTEMA: Assistente meteorolÃ³gico AI para MoÃ§ambique"');
    console.log('NOVO: " sou um assistente que entende bem como os moÃ§ambicanos falam sobre o tempo"');

    console.log('\nğŸ¯ RESULTADO ESPERADO:');
    console.log('- AnÃ¡lises mais precisas para linguagem moÃ§ambicana');
    console.log('- Respostas mais naturais e menos robÃ³ticas');
    console.log('- Melhor compreensÃ£o de contexto cultural');
    console.log('- SugestÃµes mais adequadas Ã  temperatura local');

    console.log('\nâœ… TESTE DE PROMPTS NATURAIS CONCLUÃDO!');
}

// Executar teste
testNaturalPrompts().catch(console.error);
